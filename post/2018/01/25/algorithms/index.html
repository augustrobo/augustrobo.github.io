<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Algorithms-Design and Analysis(Stanford) Notes | NOWHERESVILLE</title>
    <link rel="stylesheet" href="/css/style.css" />
    <link rel="stylesheet" href="/css/fonts.css" />
    <header>

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/ascetic.min.css">
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
  <script>hljs.initHighlightingOnLoad();</script>
  <nav>
    <ul>
      
      
      <li class="pull-left ">
        <a href="/">/home/nowheresville</a>
      </li>
      
      
      <li class="pull-left ">
        <a href="/">~/home</a>
      </li>
      
      
      <li class="pull-left ">
        <a href="/categories/">~/categories</a>
      </li>
      
      
      <li class="pull-left ">
        <a href="/tags/">~/tags</a>
      </li>
      

      
      
      <li class="pull-right">
        <a href="/index.xml">~/subscribe</a>
      </li>
      

    </ul>
  </nav>
</header>

  </head>

  <body>
    <br/>

<div class="article-meta">
<h1><span class="title">Algorithms-Design and Analysis(Stanford) Notes</span></h1>

<h2 class="date">2018/01/25</h2>
<p class="terms">
  
  
  Categories: <a href="/categories/python">Python</a> <a href="/categories/algorithms">algorithms</a> <a href="/categories/graph">graph</a> 
  
  
  
  Tags: <a href="/tags/datastructures">dataStructures</a> <a href="/tags/algorithms">algorithms</a> <a href="/tags/sorting">sorting</a> <a href="/tags/searching">searching</a> <a href="/tags/hashing">hashing</a> <a href="/tags/bloomfilters">bloomFilters</a> <a href="/tags/selection">selection</a> <a href="/tags/graph">graph</a> 
  
  
</p>
</div>


<nav id="TableOfContents">
<ul>
<li><a href="#divide-and-conquer-分而治之">Divide and Conquer 分而治之</a>
<ul>
<li><a href="#master-method">Master Method</a>
<ul>
<li><a href="#proof-recursion-tree-approach">Proof (Recursion Tree Approach)</a></li>
<li><a href="#interpretations">Interpretations</a></li>
</ul></li>
<li><a href="#counting-inversions">Counting Inversions</a>
<ul>
<li><a href="#python-code">Python Code</a></li>
</ul></li>
<li><a href="#karatsuba-multiplication">Karatsuba Multiplication</a>
<ul>
<li><a href="#python-code-1">Python Code</a></li>
</ul></li>
<li><a href="#binary-search">Binary Search</a>
<ul>
<li><a href="#python-code-2">Python Code</a></li>
</ul></li>
<li><a href="#strassen-s-matrix-multiplication">Strassen&rsquo;s Matrix Multiplication</a>
<ul>
<li><a href="#python-code-3">Python Code</a></li>
</ul></li>
<li><a href="#closest-pair">Closest Pair</a>
<ul>
<li><a href="#python-code-4">Python Code</a></li>
</ul></li>
<li><a href="#fictitious-example">Fictitious Example</a></li>
</ul></li>
<li><a href="#sorting-selection">Sorting &amp; Selection</a>
<ul>
<li><a href="#merge-sort-d-c">Merge Sort (D&amp;C)</a>
<ul>
<li><a href="#running-time">Running Time</a>
<ul>
<li><a href="#proof-by-recursion-tree-method">Proof by Recursion Tree Method</a></li>
<li><a href="#proof-by-master-method">Proof by Master Method</a></li>
</ul></li>
<li><a href="#python-code-5">Python Code</a></li>
</ul></li>
<li><a href="#quick-sort">Quick Sort</a>
<ul>
<li><a href="#partition-in-place-implementation">Partition (In-Place Implementation)</a></li>
<li><a href="#correctness-of-quicksort">Correctness of Quicksort</a></li>
<li><a href="#choice-of-pivot">Choice of Pivot</a></li>
<li><a href="#quick-sort-theorem-use-decomposition-principle">Quick Sort Theorem (Use Decomposition Principle)</a></li>
<li><a href="#python-code-6">Python Code</a></li>
</ul></li>
<li><a href="#rselect">RSelect</a></li>
<li><a href="#dselect">DSelect</a></li>
</ul></li>
<li><a href="#graph">Graph</a>
<ul>
<li><a href="#bfs">BFS</a></li>
<li><a href="#dfs">DFS</a></li>
</ul></li>
<li><a href="#hashing">Hashing</a>
<ul>
<li><a href="#bloom-filters">Bloom Filters</a></li>
</ul></li>
</ul>
</nav>


<main>


<p>PDF格式笔记见：<a href="http://augustrobo.github.io/doc/algorithms/stanford.pdf">Notes</a></p>

<h1 id="divide-and-conquer-分而治之">Divide and Conquer 分而治之</h1>

<ol>
<li><strong>DIVIDE</strong>  into smaller sub-problems</li>
<li><strong>CONQUER</strong> via recursive calls</li>
<li><strong>COMBINE</strong> solutions of sub-problems into one for the original problem</li>
</ol>

<h2 id="master-method">Master Method</h2>

<ul>
<li><p>Cool feature: a &ldquo;black-box&rdquo; method for solving recurrences</p></li>

<li><p>Determine the upper bound of <strong>running time</strong> for most of the D&amp;C algos</p></li>

<li><p><strong>Assumption</strong>: all sub-problems have equal size</p></li>
</ul>

<blockquote>
<ul>
<li>unbalanced sub-problems?</li>
<li>more than one recurrence?</li>
</ul>
</blockquote>

<ul>
<li><p><strong>Recurrence format</strong>:</p>

<ul>
<li>base case: <code>$T(n)\leq C$</code>(a constant), for all sufficiently small <code>$n$</code></li>
<li>for all larger <code>$n$</code>, <code>$T(n)\leq aT(\frac{n}{b})+O(n^d)$</code></li>
<li><code>$a$</code>: # of recurrence calls (e.g., # of sub-problems), <code>$a\geq 1$</code></li>
<li><code>$b$</code>: input size shrinkage factor, <code>$b&gt;1$</code>, <code>$T(\frac{n}{b})$</code> is the time required to solve each sub-problem</li>
<li><code>$d$</code>: exponent in running time of the combine step, <code>$d\geq 0$</code></li>
<li>constants <code>$a,b,d$</code> independent of <code>$n$</code></li>
</ul></li>

<li><p><strong>Three Cases</strong>:</p></li>
</ul>

<p>$$
T(n)=
\begin{cases}
O(n^d\log n), &amp;a=b^d \text{   (case 1)}\newline
O(n^d), &amp;a&lt;b^d\text{   (case 2)}\newline
O(n^{\log_b a}), &amp;\text{otherwise   (case 3)}
\end{cases}
$$
​   Case 1: base of logarithm does not matter</p>

<p>​   Case 3: base of logarithm matters</p>

<blockquote>
<p>If <code>$T(n)= aT(\frac{n}{b})+\Theta(n^d)$</code>, then (with similar proof)</p>

<p>$$
T(n)=
\begin{cases}
\Theta(n^d\log n), &amp;a=b^d \text{   (case 1)}\newline
\Theta(n^d), &amp;a&lt;b^d\text{   (case 2)}\newline
\Theta(n^{\log_b a}), &amp;\text{otherwise   (case 3)}
\end{cases}
$$</p>
</blockquote>

<h3 id="proof-recursion-tree-approach">Proof (Recursion Tree Approach)</h3>

<p>3 cases <code>$\Leftrightarrow$</code> 3 types of recursion trees</p>

<p>For simplicity, we assume:</p>

<ul>
<li><code>$T(1)\leq C$</code> (for some constant <code>$C$</code>)</li>
<li><code>$T(n)\leq aT(\frac{n}{b})+Cn^d$</code></li>
<li><code>$n$</code> is a power of <code>$b$</code></li>
</ul>

<p>At each level <code>$j=0,1,\ldots, \log_b n$</code>, there are</p>

<ul>
<li><code>$a^j$</code> sub-problems,</li>
<li>each of size <code>$n/b^j$</code></li>
</ul>

<blockquote>
<p><code>$(1+\log_b n)$</code> levels,  level-0: <strong>root</strong>,  level-<code>$\log_b n$</code>: <strong>leaves</strong></p>
</blockquote>

<p>Then
$$
\text{Total work at level-}j \leq
a^j \times C\left(\frac{n}{b^j}\right)^d
$$
Thus,
$$
\text{Total work} \leq Cn^d\sum_{j=0}^{\log_bn}\left(\frac{a}{b^d}\right)^j   \ \ (\Delta)
$$
<code>$\Rightarrow$</code> all depends on the relationship between <code>$a$</code> and <code>$b^d$</code></p>

<blockquote>
<p>For constant <code>$r&gt;0$</code>,
$$
1+r+r^2+\cdots+r^k = \frac{1-r^{k+1}}{1-r} \leq
\begin{cases}
\frac{1}{1-r}, &amp;r<1 \newline
\frac{r}{r-1} r^k, &r>1
\end{cases}
$$</p>

<ul>
<li><code>$0&lt;r&lt;1$</code>, <code>$LHS \leq Constant$</code></li>
<li><code>$r&gt;1$</code>, <code>$LHS$</code> is dominated by the largest power of <code>$r$</code></li>
</ul>
</blockquote>

<p><strong>Case 1</strong>. <code>$a=b^d$</code>
$$
(\Delta) \leq Cn^d\times log_b n=O(n^d\log n)
$$</p>

<p><strong>Case 2</strong>. <code>$a&lt;b^d$</code></p>

<p>$$
(\Delta) \leq O(n^d)
$$
<strong>Case 3</strong>. <code>$a&gt;b^d$</code>
$$
(\Delta)\leq Cn^d \left(\frac{a}{b^d}\right)^{\log_b n}= Ca^{\log_b n}=Cn^{\log_b a}=O(n^{\log_b a})
$$</p>

<blockquote>
<p><code>$n^{\log_ba}=a^{\log_bn} \Leftrightarrow\log_ba\log_bn=\log_bn\log_ba$</code></p>
</blockquote>

<p><code>$a^{\log_b n}=$</code> # of leaves</p>

<h3 id="interpretations">Interpretations</h3>

<p>Upper bound on the work at level <code>$j$</code>:
$$
Cn^d\times\left(\frac{a}{b^d}\right)^j
$$</p>

<p>$$
a:\text{ rate of sub-problem poliferation, RSP - force of evil} \\<br />
b^d: \text{rate of work shrinkage (per sub-problem), RWS - force of good}
$$</p>

<ul>
<li><code>$RSP&lt;RWS$</code>

<ul>
<li>amount of work is decreasing with the recursion level <code>$j$</code></li>
<li>most work at root <code>$\Rightarrow$</code> root dominates <code>$\Rightarrow$</code> might expect <code>$O(n^d)$</code></li>
</ul></li>
<li><code>$RSP&gt;RWS$</code>

<ul>
<li>amount of work is increasing with the recursion level <code>$j$</code></li>
<li>leaves dominate <code>$\Rightarrow$</code> might expect <code>$O(\#\text{leaves})=O(a^{\log_b n})=O(n^{\log_b a})$</code></li>
</ul></li>
<li><code>$RSP=RWS$</code>

<ul>
<li>amount of work is the same at each recursion level <code>$j$</code> (like merge sort)</li>
<li>might expect <code>$O(\log n)\times O(n^d)=O(n^d\log n)$</code> (recursion depth = <code>$O(\log n)$</code>)</li>
</ul></li>
</ul>

<h2 id="counting-inversions">Counting Inversions</h2>

<ul>
<li><strong>Problem</strong>: counting # of inversions in an array = # of pairs <code>(i,j)</code> of array indices with <code>i&lt;j</code> and <code>A[i]&gt;A[j]</code></li>
<li>Number of inversions = Number of intersections of line segments</li>
</ul>

<p><a href="https://i.stack.imgur.com/uScHd.png"><img src="https://i.stack.imgur.com/uScHd.png" alt="enter image description here" /></a></p>

<ul>
<li><strong>Application</strong>: measuring similarity between 2 ranked lists =&gt; making good recommendations =&gt; <strong>collaborative filtering</strong> (CF)</li>
<li>Largest possible number of inversions that an <code>$n$</code>-element array can have? <code>$C_n^2$</code> (worst case: array in backward order)</li>
<li><strong>Brute-force</strong> algorithm: <code>$O(n^2)$</code></li>
<li><strong>D&amp;C</strong> algorithm:  pseudocode</li>
</ul>

<blockquote>
<p>A  = input array [length = n]</p>

<p>D = output [length=<code>n</code>]</p>

<p>B = 1st sorted array [<code>n/2</code>], C = 2nd sorted array [<code>n/2</code>]</p>

<pre><code>SortAndCount(A)
  if n=1, return 0
  else
      (B,X) = SortAndCount(1st half of A)
      (C,Y) = SortAndCount(2nd half of A)
      (D,Z) = MergeAndCountSplitInv(A)
  return X + Y + Z
</code></pre>

<p><strong>Goal</strong>: implement <code>MergeAndCountSplitInv</code> in linear time <code>$O(n)$</code></p>

<p>The split inversions involving an element y of the 2nd array C are precisely the elements left in the 1st array B when y is copied to the output D.</p>
</blockquote>

<p>$$
T(n)\leq 2T\left(\frac{n}{2}\right)+O(n) \Rightarrow T(n)=O(n\log n)
$$</p>

<h3 id="python-code">Python Code</h3>

<pre><code class="language-python">def sortAndCount(arr):
        n = len(arr)
        # base case
        if n &lt; 2:
            return arr, 0

        m = n//2
        left, x = sortAndCount(arr[:m])
        right, y = sortAndCount(arr[m:])

        i = j = z = 0
        for k in range(n):
            if j == n-m or (i &lt; m and left[i] &lt; right[j]):
                arr[k] = left[i]
                i += 1
            else:
                arr[k] = right[j]
                j += 1
                z += (m - i)
        return arr, x + y + z
</code></pre>

<h2 id="karatsuba-multiplication">Karatsuba Multiplication</h2>

<ul>
<li><strong>Problem</strong>: multiplication of  two <code>$n$</code>-digit numbers <code>$x, y$</code> (base 10)</li>
<li><strong>Application</strong>: cryptography</li>
<li>Define <em>primitive operations</em>:  add or multiply 2 single-digit numbers</li>
<li>Simple method: <code>$\leq 4n^2 = O(n^2)$</code> operations</li>
<li><strong>Recursive method</strong>:</li>
</ul>

<p>$$
x = 10^{n/2}a+b, y = 10^{n/2}c+d, \text{ where }a,b,c,d\text{ are }\frac{n}{2}-\text{digit numbers}
$$</p>

<p>$$
\Rightarrow xy = 10^nac+ 10^{n/2}(ad+bc)+bd\ \ \ \ \ \  (*)
$$</p>

<p><strong>Algorithm #1 (Naive method)</strong></p>

<blockquote>
<ul>
<li>recursively compute <code>$ac$</code>, <code>$ad$</code>, <code>$bc$</code>, and <code>$bd$</code></li>
<li>then compute (*)</li>
</ul>
</blockquote>

<p><strong>Running time</strong>
$$
T(n)
\begin{cases}
=O(1), &amp;n=1(\text{base case})\newline
\leq 4T(\frac{n}{2}) + O(n), &amp;n\geq 1(\text{4 subproblems and linear time bit addition})
\end{cases}
$$
By master method,</p>

<p>$$
a = 4 &gt; 2^1 = b^d (\text{case 3}) \Rightarrow T(n) = O(n^{\log_ba})=O(n^2)
$$
<strong>Algorithm #2 (Gauss method)</strong></p>

<blockquote>
<ul>
<li>recursively compute <code>$ac$</code>, <code>$bd$</code>, <code>$(a+b)(c+d)$</code></li>
<li><code>$ad+bc = (a+b)(c+d)-(ac+bd)$</code></li>
<li>then compute (*)</li>
</ul>
</blockquote>

<p><strong>Running time</strong>
$$
T(n)
\begin{cases}
=O(1), &amp;n=1(\text{base case})\newline
\leq 3T(\lceil \frac{n}{2} \rceil) + O(n), &amp;n\geq 1(\text{3 subproblems and linear time bit addition})
\end{cases}
$$
By master method,</p>

<p>$$
a = 3 &gt; 2^1 = b^d (\text{case 3}) \Rightarrow T(n) = O(n^{\log_ba})=O(n^{\log_23})=O(n^{1.59})
$$
Better than simple method!</p>

<h3 id="python-code-1">Python Code</h3>

<pre><code class="language-python">def karatsuba(x, y):
    nx, ny = len(str(x)), len(str(y))
    n = max(nx, ny)

    # base case
    if n == 1:
        return x*y

    m = n//2
    bm = 10**m
    a, b = x//bm, x%bm
    c, d = y//bm, y%bm
    term1 = karatsuba(a, c)
    term2 = karatsuba(b, d)
    term3 = karatsuba(a+b, c+d)
    result = (bm**2)*term1 + bm*(term3 - term1 - term2) + term2
    return result
</code></pre>

<h2 id="binary-search">Binary Search</h2>

<ul>
<li><strong>Problem</strong>: looking for an element in a given sorted array</li>
<li><strong>Running time</strong>: <code>$T(n)=T(n/2)+O(1)$</code>. By master method,</li>
</ul>

<p>$$
a = 1=2^0=b^d \text{ (case 1) }\Rightarrow T(n)\leq O(n^d\log n)=O(\log n)
$$</p>

<h3 id="python-code-2">Python Code</h3>

<p>See <a href="https://augustrobo.github.io/post/2018/01/01/searching/#binary-search">link</a></p>

<h2 id="strassen-s-matrix-multiplication">Strassen&rsquo;s Matrix Multiplication</h2>

<ul>
<li><strong>Problem</strong>: compute <code>$Z_{n\times n}=X_{n\times n}\cdot Y_{n\times n}$</code> (Note: input size = <code>$O(n^2)$</code>)</li>
<li>Naive iterative algorithm: <code>$O(n^3)$</code> (3 <code>for</code> loops)</li>
</ul>

<p>$$
z_{ij} = \sum_{k=1}^n x_{ik}\cdot y_{kj}
$$</p>

<ul>
<li>Write</li>
</ul>

<p>$$
X = \begin{pmatrix}
A &amp;B\newline
C &amp;D
\end{pmatrix},
Y = \begin{pmatrix}
E &amp;F\newline
G &amp;H
\end{pmatrix}
$$</p>

<p>where <code>$A$</code> through <code>$H$</code> are all <code>$\frac{n}{2}\times \frac{n}{2}$</code> matrices. Then
$$
X\cdot Y = \begin{pmatrix}
AE+BG &amp;AF+BH\newline
CE+DG &amp;CF+DH
\end{pmatrix}
$$</p>

<ul>
<li>Recursive method #1:

<ul>
<li><strong>step1</strong>. recursively compute the 8 products</li>
<li><strong>step2</strong>. do additions (<code>$O(n^2)$</code> time)</li>
<li><strong>Running time</strong>: by master method,</li>
</ul></li>
</ul>

<p>$$
a = 8&gt;2^2=b^d \text{ (case 3) }\Rightarrow T(n)\leq O(n^{\log_b a})=O(n^{\log_2 8})=O(n^{3})
$$</p>

<ul>
<li><strong>Strassen&rsquo;s method</strong>:

<ul>
<li><strong>step1</strong>. recursively compute only 7 (cleverly chosen) products</li>
<li><strong>step2</strong>. do (clever) additions (<code>$O(n^2)$</code> time)</li>
<li><strong>Running time</strong>: by master method,</li>
</ul></li>
</ul>

<p>$$
a = 7&gt;2^2=b^d \text{ (case 3) }\Rightarrow T(n)\leq O(n^{\log_b a})=O(n^{\log_2 7})=O(n^{2.81})
$$</p>

<blockquote>
<p>The 7 products:
$$
P_1 =A(F-H)\\<br />
P_2 =(A+B)H\\<br />
P_3=(C+D)E\\<br />
P_4=D(G-E)\\<br />
P_5=(A+D)(E+H)\\<br />
P_6=(B-D)(G+H)\\<br />
P_7=(A-C)(E+F)
$$</p>

<p>Then
$$
\begin{align}
X\cdot Y &amp;= \begin{pmatrix}
AE+BG &amp;AF+BH\newline
CE+DG &amp;CF+DH
\end{pmatrix}\newline
&amp;=
\begin{pmatrix}
P_5+P_4-P_2+P_6 &amp;P_1+P_2\newline
P_3+P_4 &amp;P_1+P_5-P_3-P_7
\end{pmatrix}
\end{align}
$$</p>
</blockquote>

<h3 id="python-code-3">Python Code</h3>

<pre><code class="language-python">import numpy as np
def strassen(X, Y):
    n = X.shape[0]
    if n == 1:
        return np.array([X[0, 0]*Y[0, 0]])
    
    if n%2 == 1: # padding with zeros
        Xpad = np.zeros((n + 1, n + 1))
        Ypad = np.zeros((n + 1, n + 1))
        Xpad[:n, :n], Ypad[:n, :n] = X, Y
        return strassen(Xpad, Ypad)[:n, :n]
    
    m = n//2
    A, B, C, D = X[:m, :m], X[:m, m:], X[m:, :m], X[m:, m:]
    E, F, G, H = Y[:m, :m], Y[:m, m:], Y[m:, :m], Y[m:, m:]
  
    P1 = strassen(A, F - H)
    P2 = strassen(A + B, H)
    P3 = strassen(C + D, E)
    P4 = strassen(D, G - E)
    P5 = strassen(A + D, E + H)
    P6 = strassen(B - D, G + H)
    P7 = strassen(A - C, E + F)
    
    Z = np.zeros((n, n))
    Z11 = P5 + P4 - P2 + P6
    Z12 = P1 + P2
    Z21 = P3 + P4
    Z22 = P1 + P5 - P3 - P7
    
    Z[:m, :m], Z[:m, m:], Z[m:, :m], Z[m:, m:] = Z11, Z12, Z21, Z22

    return Z
</code></pre>

<h2 id="closest-pair">Closest Pair</h2>

<ul>
<li><strong>Input</strong>: a set <code>$P=\{p_1,\ldots,p_n\}$</code> of <code>$n$</code> points in the plane (<code>$\mathbb{R}^2$</code>)</li>
<li>Notation: <code>$d(p,q) = $</code> Euclidean distance</li>
<li><strong>Output</strong>: <code>$p^*, q^*=\arg\min\limits_{p\neq q\in P}d(p,q)$</code></li>
<li><strong>Assumption</strong>: (for convenience) all points have distinct <code>$x$</code>-coordinates, <code>$y$</code>-coordinates</li>
<li><strong>Brute-force search</strong>:  <code>$\Theta(n^2)$</code></li>
<li>1-d version of CP:

<ul>
<li>sort points (<code>$O(n\log n)$</code> time)</li>
<li>return CP of adjacent points (<code>$O(n)$</code> time)</li>
</ul></li>
<li><strong>Goal</strong>: <code>$O(n\log n)$</code> time algo for 2-d version</li>
<li><strong>D&amp;C</strong>: make copies of points sorted by <code>$x$</code>-coordinates (<code>$P_x$</code>) and by <code>$y$</code>-coordinates (<code>$P_y$</code>) [<code>$O(n\log n)$</code> time]</li>
</ul>

<blockquote>
<p><code>ClosestPair</code> <code>$(P_x, P_y)$</code></p>

<ol>
<li><code>$Q$</code> = left half of <code>$P$</code>, <code>$R$</code> = right half of <code>$P$</code>. Form <code>$Q_x, Q_y, R_x, R_y$</code> [<code>$O(n)$</code> time]</li>
<li><code>$(p_1,q_1)=$</code> <code>ClosestPair</code> <code>$(Q_x, Q_y)$</code></li>
<li><code>$(p_2,q_2)=$</code> <code>ClosestPair</code> <code>$(R_x, R_y)$</code></li>
<li>let <code>$\delta = \min\{d(p_1,q_1), d(p_2,q_2)\}$</code></li>
<li><code>$(p_3,q_3)=$</code> <code>ClosestSplitPair</code> <code>$(P_x, P_y, \delta)$</code>. Requirements:

<ul>
<li><code>$O(n)$</code> time</li>
<li>correct whenever CP of <code>$P$</code> is a split pair</li>
</ul></li>
<li>return best of <code>$(p_1,q_1),(p_2,q_2),(p_3,q_3)$</code></li>
</ol>

<p><code>ClosestSplitPair</code> <code>$(P_x, P_y, \delta)$</code></p>

<p><strong>filtering</strong> + <strong>linear scan</strong></p>

<ol>
<li>Let <code>$\bar{x}$</code> = biggest <code>$x$</code>-coordinate in the left of <code>$P$</code> [<code>$O(1)$</code> time]</li>
<li>Let <code>$S_y$</code> = points of <code>$P$</code> with <code>$x$</code>-coordinate in <code>$[\bar{x}-\delta,\bar{x}+\delta]$</code>, sorted by <code>$y$</code>-coordinate</li>
<li>Initialize best = <code>$\delta$</code>, best point = <code>NULL</code>, <code>$m=\vert S_y\vert$</code>.</li>
</ol>

<pre><code>   For i = 1 to m-1
      For j = 1 to min(7, m-i)
          Let p, q = ith, (i+j)th points of P
          If d(p, q) &lt; best
              best point = (p, q)
              best = d(p, q)
</code></pre>

<p>[<code>$O(n)$</code> time]</p>
</blockquote>

<p><strong>Claim</strong>. Let <code>$p\in Q$</code>, <code>$q\in R$</code> be a split pair with <code>$d(p,q)&lt;\delta$</code>. Then</p>

<p>(A) <code>$p,q\in S_y$</code></p>

<p>(B) <code>$p,q$</code> are at most 7 positions apart in <code>$S_y$</code></p>

<blockquote>
<p><strong>Proof.</strong></p>

<p>(A) Let <code>$p=(x_1,y_1)\in Q, q = (x_2, y_2)\in R$</code> and <code>$d(p,q)&lt;\delta$</code>. Thus, <code>$|x_1-x_2|&lt;\delta$</code>.
$$
\Rightarrow x_1 \leq \bar{x} \leq x_2 \Rightarrow \begin{cases}
\bar{x}-x_1\leq x_2-x_1 &lt;\delta &amp;\Rightarrow x_1 &gt;\bar{x}-\delta \newline
x_2-\bar{x}\leq x_2-x_1 &lt;\delta &amp;\Rightarrow x_2 &lt;\bar{x} +\delta
\end{cases}
$$
(B) Evenly divide <code>$[\bar{x}-\delta, \bar{x}+\delta]\times [\tilde{y}, \tilde{y}+\delta]$</code> into 8 <code>$\frac{\delta}{2}\times \frac{\delta}{2}$</code> boxes, where <code>$\tilde{y}=\min\{y_1,y_2\}$</code>.</p>

<p>Then at most 1 point in each of the 8 boxes.</p>

<p>Proof by contradiction.</p>

<p>Let <code>$a,b$</code> be in the same box. Then <code>$a,b\in Q$</code> or <code>$a,b\in R$</code>.
$$
d(a,b)\leq \frac{\delta}{\sqrt{2}}&lt;\delta. \ \ \text{contradiction to definition of }\delta.
$$</p>
</blockquote>

<p><strong>Corollary1</strong>. If CP of <code>$P$</code> is a split pair, then <code>ClosestSplitPair</code> can find it.</p>

<p><strong>Corollary2</strong>. <code>ClosestPair</code> is correct, and runs in <code>$O(n\log n)$</code> time.</p>

<h3 id="python-code-4">Python Code</h3>

<pre><code class="language-python">import numpy as np
import numpy.linalg as LA
# find closet pair of n 2-dim points
# use n * 2 dim np array P
# each row: 1 point

def CP(P):
    Px = P[P[:, 0].argsort(kind = 'mergesort')]
    Py = P[P[:, 1].argsort(kind = 'mergesort')]
    return closestPair(Px, Py)

def closestPair(Px, Py):
    n = Px.shape[0] # no of points
    if n &lt; 4:
        return bruteForceCP(Px)

    mid = n//2
    Qx, Rx = Px[:mid], Px[mid:]
    midx = Px[mid, 0]
    idx = (Py[:, 0] &lt; midx)
    Qy, Ry = Py[idx], Py[~idx]
    (p1, q1), r1 = closestPair(Qx, Qy)
    (p2, q2), r2 = closestPair(Rx, Ry)

    if r1 &lt; r2:
        best = r1
        bestpoint = (p1, q1)
    else:
        best = r2
        bestpoint = (p2, q2)

    (p3, q3), r3 = closestSplitPair(Px, Py, best, bestpoint)
    if r3 &lt; best:
        best = r3
        bestpoint = (p3, q3)
    return bestpoint, best

def bruteForceCP(P):
    best = float('Inf')
    bestpoint = None
    n = P.shape[0]
    for i in range(n):
        for j in range(i + 1, n):
            d = LA.norm(P[i] - P[j])
            if d &lt; best:
                best = d
                bestpoint = (P[i], P[j])
    return bestpoint, best

def closestSplitPair(Px, Py, best, bestpoint):
    n = Px.shape[0]
    mid = n//2
    midx = Px[mid, 0]
    idx = np.logical_and(midx - best &lt;= Py[:, 0], Py[:, 0] &lt;= midx + best)
    Sy = Py[idx]

    m = Sy.shape[0] # no of points in Sy
    for i in range(m - 1):
        for j in range(i + 1, min(i + 8, m)):
            p, q = Sy[i], Sy[j]
            d = LA.norm(p - q)
            if d &lt; best:
                best = d
                bestpoint = (p, q)
    return bestpoint, best

# Test
import time
a = np.random.randint(1e5, size = (1000, 2))
tic = time.time()
b = bruteForceCP(a)
toc = time.time()
print(&quot;Brute Force takes time:&quot;, toc - tic)
print(&quot;ans:&quot;, b)
# Brute Force takes time: 4.079403400421143
# ans: ((array([29326, 36462]), array([29246, 36561])), 127.283148923964)

tic = time.time()
c = CP(a)
toc = time.time()
print(&quot;D&amp;C takes time:&quot;, toc - tic)
print(&quot;ans:&quot;, c)
# D&amp;C takes time: 0.14911723136901855
# ans: ((array([29326, 36462]), array([29246, 36561])), 127.283148923964)
</code></pre>

<h2 id="fictitious-example">Fictitious Example</h2>

<p>$$
T(n)=2T\left(\frac{n}{2}\right) + O(n^2) \\<br />
    \Rightarrow a=2&lt;2^2=b^d (\text{case 2}) \Rightarrow T(n)=O(n^2)
$$</p>

<p>Recursion depth = <code>$O(\log n)$</code>, each level <code>$O(n^2)$</code>.</p>

<p><code>$T(n)=O(n^2)=o(n^2\log n)$</code>! Master method gives <strong>a tighter upper bound</strong>!</p>

<h1 id="sorting-selection">Sorting &amp; Selection</h1>

<table>
<thead>
<tr>
<th align="center"></th>
<th align="center">SORTING</th>
<th align="center">SELECTION</th>
</tr>
</thead>

<tbody>
<tr>
<td align="center"><strong>Randomized</strong></td>
<td align="center">Quick Sort</td>
<td align="center">RSelect</td>
</tr>

<tr>
<td align="center"><strong>Deterministic</strong></td>
<td align="center">Merge Sort</td>
<td align="center">DSelect</td>
</tr>
</tbody>
</table>

<p><strong>Merge Sort versus Quick Sort</strong></p>

<ul>
<li>Quick Sort has a smaller constant than Merge Sort</li>
</ul>

<table>
<thead>
<tr>
<th align="center">Running Time</th>
<th align="center"><em>Average Case</em></th>
<th align="center"><em>Worst Case</em></th>
</tr>
</thead>

<tbody>
<tr>
<td align="center"><strong><em>Merge Sort</em></strong></td>
<td align="center"><code>$O(n\log n)$</code></td>
<td align="center"><code>$O(n\log n)$</code></td>
</tr>

<tr>
<td align="center"><strong><em>Quick Sort</em></strong></td>
<td align="center"><code>$O(n\log n)$</code></td>
<td align="center"><code>$O(n^2)$</code></td>
</tr>
</tbody>
</table>

<h2 id="merge-sort-d-c">Merge Sort (D&amp;C)</h2>

<ul>
<li><strong>Input</strong>: array of numbers (assume distinct, <strong>exercise</strong>: duplicate case), unsorted</li>
<li><strong>Output</strong>: same numbers, sorted in increasing order</li>
<li><strong>Pseudocode for Merge</strong>:</li>
</ul>

<blockquote>
<p>C = output [length=<code>n</code>]</p>

<p>A = 1st sorted array [<code>n/2</code>], B = 2nd sorted array [<code>n/2</code>]</p>

<p><code>i = 1, j = 1</code></p>

<pre><code>for k = 1 to n
  if A(i)&lt;B(j)
      C(k)=A(i)
      i++
  else [B(j)&lt;A(i)]
      C(k)=B(j)
      j++
end 
</code></pre>

<p>(ignores end cases)</p>
</blockquote>

<h3 id="running-time">Running Time</h3>

<ul>
<li><strong>Key question</strong>: running time of <strong>Merge Sort</strong> on array of <code>$n$</code> numbers?</li>
<li><strong>Upshot</strong>: running time of <strong>Merge</strong> on an array of <code>$m$</code> numbers <code>$\leq 5m+2\leq 6m (m&gt;1)$</code></li>
</ul>

<blockquote>
<p><code>i = 1</code>, <code>j = 1</code> [2 operations]</p>

<p>each <strong>for</strong> loop: comparison, assignment, increment of <code>i</code> or <code>j</code>, increment of <code>k</code>, comparison of <code>k</code> to the upper bound <code>n</code></p>
</blockquote>

<ul>
<li><strong>Claim</strong>: Merge Sort requires <code>$\leq 6n\log_2n+6n$</code> operations to sort <code>$n$</code> numbers.</li>
</ul>

<h4 id="proof-by-recursion-tree-method">Proof by Recursion Tree Method</h4>

<ul>
<li><p>Assume <code>$n$</code> = power of 2</p></li>

<li><p>At each level <code>$j=0,1,2,\cdots,\log_2 n$</code>, there are <code>$2^j$</code> sub-problems, each of size <code>$n/2^j$</code>.</p></li>

<li><p>Total # of operations at level <code>$j$</code> (<strong>Merge</strong>):
$$
\leq 2^j \times 6\left(\frac{n}{2^j}\right)=6n \text{ (independent of }j)
$$</p></li>

<li><p>Total # of operations <code>$\leq 6n(\log_2 n +1)$</code></p></li>
</ul>

<h4 id="proof-by-master-method">Proof by Master Method</h4>

<p>$$
a = 2=2^1=b^d \text{ (case 1) }\Rightarrow T(n)\leq O(n^d\log n)=O(n\log n)
$$</p>

<h3 id="python-code-5">Python Code</h3>

<pre><code class="language-python">def mergeSort(arr):
    n = len(arr)
    # base case
    if n &lt; 2:
        return arr[:]

    m = n//2
    left, right = mergeSort(arr[:m]), mergeSort(arr[m:])
    left.append(float('Inf'))
    right.append(float('Inf'))
    i = j = 0
    result = []
    for k in range(n):
        if left[i] &lt; right[j]:
            result.append(left[i])
            i += 1
        else:
            result.append(right[j])
            j += 1
    return result
</code></pre>

<ul>
<li>Space complexity: <code>$O(n)$</code></li>
</ul>

<h2 id="quick-sort">Quick Sort</h2>

<ul>
<li><p>a randomized algorithm,  <code>$O(n\log n)$</code> time on average, works in place <code>$O(1)$</code></p></li>

<li><p><strong>Input</strong>: array of numbers (assume distinct, <strong>exercise</strong>: duplicate case), unsorted</p></li>

<li><p><strong>Output</strong>: same numbers, sorted in increasing order</p></li>

<li><p><strong>key idea</strong>: partition array around a pivot element</p>

<ul>
<li>pick pivot</li>
<li>rearrange array so that pivot in its &lsquo;<strong>rightful</strong>&rsquo; position

<ul>
<li>left of pivot: less than pivot</li>
<li>right of pivot: greater than pivot</li>
</ul></li>
</ul></li>

<li><p>cool facts about partition:</p>

<ul>
<li><p>linear time <code>$O(n)$</code>, no extra space</p></li>

<li><p>reduces problem size</p></li>
</ul></li>

<li><p><strong>High-Level Description</strong></p></li>
</ul>

<blockquote>
<p><strong>Quick Sort</strong></p>

<ul>
<li>Input: array <code>A</code>, length <code>n</code></li>
<li>if <code>n = 1</code>, return</li>
<li><code>p = choosePivot(A, n)</code></li>
<li>partition <code>A</code> around <code>p</code></li>
<li>recursively sort 1st part</li>
<li>recursively sort 2nd part</li>
</ul>
</blockquote>

<h3 id="partition-in-place-implementation">Partition (In-Place Implementation)</h3>

<ul>
<li>Assume: pivot be the 1st element in arr [if not, swap pivot <code>$\leftrightarrow$</code> 1st element as preprocessing step]</li>
<li><strong>High-Level Idea</strong>

<ul>
<li>single scan thru arr</li>
<li>invariant: everything looked at so far is partitioned</li>
</ul></li>
<li>Pseudocode for partition:</li>
</ul>

<blockquote>
<p><code>Partition(A, l, r)</code></p>

<pre><code>p := A[l]
i : = l + 1
for j = l + 1 to r:
  if A[j] &lt; p:
      swap A[j], A[i]
      i += 1
swap A[l] and A[i-1]
</code></pre>
</blockquote>

<ul>
<li>running time: <code>$O(n), n=r-l+1$</code></li>
<li>works in space <code>$O(1)$</code></li>
</ul>

<h3 id="correctness-of-quicksort">Correctness of Quicksort</h3>

<p><code>$P(n)$</code> = &ldquo;Quick Sort correctly sorts every input array of length <code>$n$</code>&ldquo;</p>

<p><strong>Claim</strong>: <code>$P(n)$</code> holds for every <code>$n\geq 1$</code>. [no matter how pivot is chosen]</p>

<blockquote>
<p><strong>Proof by induction</strong>.</p>

<ul>
<li>base case: every input array of length 1 is already sorted. <code>$P(1)$</code> holds.</li>
<li>inductive step: Fix <code>$n\geq 2$</code>. Fix some input array A of length <code>$n$</code>.</li>
</ul>

<p>Need to show: if <code>$P(k)$</code> holds <code>$\forall k\leq n$</code>, then <code>$P(n)$</code> holds as well.</p>

<p>Quick Sort first partitions A around some pivot p.</p>

<p>Pivot winds up in correct position.</p>

<p>Let <code>$k_1, k_2$</code> be lengths of 1st, 2nd parts of partitioned array.</p>

<p>Since <code>$k_1&lt;n, k_2&lt;n$</code>, by inductive hypothesis, 1st, 2nd parts get sorted correctly by recursive calls.</p>

<p>So after recursive calls, entire array is correctly sorted.</p>
</blockquote>

<h3 id="choice-of-pivot">Choice of Pivot</h3>

<ul>
<li>Running time of Quick Sort?

<ul>
<li>Depends on the quality of the pivot.</li>
</ul></li>
<li>What is the running time of QS on an already <strong>sorted</strong> array if <code>choosePivot</code> always selects the <strong>first</strong> element of the array? 【Worst case】

<ul>
<li><code>$O(n^2)$</code></li>
</ul></li>
<li>Best case: every recursive call chooses the median element of its subarray as its pivot. Running time?

<ul>
<li><code>$O(n\log n)$</code></li>
<li><code>$T(n)\leq 2T(\frac{n}{2})+O(n)\ \ \Rightarrow\ \ T(n)=O(n\log n) $</code>  (master method)</li>
</ul></li>
<li>key question: how to choose pivots?

<ul>
<li>big idea: <strong>random pivots</strong></li>
</ul></li>
<li>Intuition:

<ul>
<li>if always get a 25-75 split, good enough for <code>$O(n\log n)$</code> running time. (<strong>prove via recursion tree</strong>)</li>
<li>half of elements give a 25-75 split or better</li>
</ul></li>
</ul>

<h3 id="quick-sort-theorem-use-decomposition-principle">Quick Sort Theorem (Use Decomposition Principle)</h3>

<p>Theorem: for every input array length <code>$n$</code>, the average running time of Quick Sort (with random pivots) is <code>$O(n\log n)$</code>. 【&rdquo;average&rdquo; is over random choices made by the algorithm (i.e. pivot choices)】</p>

<p><strong>Proof.</strong></p>

<hr />

<p>Fix input array A of length <code>$n$</code>.</p>

<p>Sample space <code>$\Omega$</code> = all possible outcomes of random choices in Quick Sort. (i.e. pivot sequences)</p>

<p><strong>Key random variable</strong>: for <code>$\sigma\in\Omega$</code>,
$$
C(\sigma)=\text{# of comparisons between 2 input elements made by Quick Sort given random choices }\sigma
$$</p>

<p><strong>Lemma</strong>. Running time of Quick Sort is dominated by comparisons.
$$
\Rightarrow \exists \text{ constant } d, \ \forall \sigma\in\Omega, \ RT(\sigma) \leq d\cdot C(\sigma)
$$
<strong>Remaining goal</strong>: prove <code>$E[C]=O(n\log n)$</code>.</p>

<p><strong>Notation</strong>: <code>$z_i= ith$</code> smallest element of A.</p>

<p>For <code>$\sigma\in \Omega$</code>, indices <code>$i&lt;j$</code>, let
$$
X_{ij}=\text{ # of times } z_i, z_j \text{ get compared in Quick Sort with pivot sequence }\sigma
$$</p>

<p>$$
\Rightarrow X_{ij} = 0 \text{ or } 1 \text{ (indicator variable)} = \mathbb{1}(z_i, z_j \text{ get compared with }\sigma)
$$</p>

<p>Then, <code>$\forall \sigma$</code>,
$$
C(\sigma) = \sum_{i=1}^n\sum_{j=i+1}^n X_{ij}(\sigma)
$$
By linearity of expectation,
$$
E[C] = \sum_{i=1}^{n-1}\sum_{j=i+1}^n E[X_{ij}]= \sum_{i=1}^{n-1} \sum_{j=i+1}^n\Pr(X_{ij}=1)\ \ \ (*)
$$
<strong>Key claim</strong>: <code>$\forall i&lt;j$</code>, <code>$\Pr(X_{ij}=1)=\Pr(z_i, z_j \text{ get compared})=\frac{2}{j-i+1}$</code></p>

<p>As long as none of <code>$z_i,z_{i+1},\ldots,z_j$</code>  are chosen as a pivot, all are passed to the same recursive call.</p>

<p>Consider the first among <code>$z_i,z_{i+1},\ldots,z_j$</code> that gets chosen as a pivot.</p>

<ul>
<li>if <code>$z_i$</code> or <code>$z_j$</code> gets chosen first, then <code>$z_i$</code> and <code>$z_j$</code> get compared.</li>
<li>otherwise,  then <code>$z_i$</code> and <code>$z_j$</code> are never compared compared.</li>
</ul>

<p>Note: since pivots always chosen uniformly at random, each of <code>$z_i,z_{i+1},\ldots,z_j$</code> is equally likely to be the first.
$$
\Rightarrow \Pr(z_i, z_j \text{ get compared}) = \frac{2}{j-i+1}
$$</p>

<p>$$
\Rightarrow E[C]=2\sum_{i=1}^{n-1}\sum_{j=i+1}^n \frac{1}{j-i+1}\leq 2n\sum_{k=2}^n\frac{1}{k}\leq 2n\log n
$$</p>

<p>$$
\sum_{k=2}^n\frac{1}{k}=\sum_{k=2}^n\int_{k-1}^k\frac{1}{k}dx&lt; \sum_{k=2}^n\int_{k-1}^k\frac{1}{x}dx=\int_{1}^n\frac{1}{x}dx=\log n.
$$</p>

<hr />

<h3 id="python-code-6">Python Code</h3>

<pre><code class="language-python">from random import randint

def partition(arr, L, R):
    pivot = arr[L]
    i = L + 1
    for j in range(i, R + 1):
        if arr[j] &lt; pivot:
            arr[j], arr[i] = arr[i], arr[j]
            i += 1
    arr[L], arr[i - 1] = arr[i - 1], arr[L]
    return i - 1

def quickSortHelper(arr, L, R):
    if R - L &lt; 1:
        return arr
    pos = randint(L, R)
    arr[L], arr[pos] = arr[pos], arr[L]
    pos = partition(arr, L, R)
    quickSortHelper(arr, L, pos - 1)
    quickSortHelper(arr, pos + 1, R)

def quickSort(arr):
    return quickSortHelper(arr, 0, len(arr) - 1)
</code></pre>

<h2 id="rselect">RSelect</h2>

<h2 id="dselect">DSelect</h2>

<h1 id="graph">Graph</h1>

<h2 id="bfs">BFS</h2>

<h2 id="dfs">DFS</h2>

<h1 id="hashing">Hashing</h1>

<h2 id="bloom-filters">Bloom Filters</h2>

</main>

    <footer>
      <script type="text/javascript" async
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
  });
  MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });

  MathJax.Hub.Config({
  
  TeX: { equationNumbers: { autoNumber: "AMS" } }
  });
</script>

<script src="//yihui.name/js/math-code.js"></script>
<script async src="//cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

<script async src="//yihui.name/js/center-img.js"></script>

      
      <hr/>
      <a href="mailto:zhuxm2017@163.com">Email</a> | <a href="https://github.com/augustrobo">Github</a>
      
    </footer>
  </body>
</html>

