<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on NOWHERESVILLE</title>
    <link>/categories/python/</link>
    <description>Recent content in Python on NOWHERESVILLE</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 01 Feb 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Data Manipulation at Scale 大规模数据处理</title>
      <link>/post/2018/02/01/data-manipulation-at-scale/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/02/01/data-manipulation-at-scale/</guid>
      <description>课程介绍  Data Manipulation at Scale: Systems and Algorithms 大规模数据处理：系统和算法【 Coursera链接 】 Data Science at Scale Specialization 的第一门课，共4门 制作方： University of Washington 教学方： Bill Howe  Twitter Sentiment Analysis 情感分析 分析目的  access the twitter Application Programming Interface(API) using python estimate the public&amp;rsquo;s perception (the sentiment) of a particular term or phrase analyze the relationship between location and mood based on a sample of twitter data  步骤  CLI安装 oauth2 package [用于授权登录]  pip3 install oauth2   创建 twitter 账号 到 https://apps.</description>
    </item>
    
    <item>
      <title>Algorithms-Design and Analysis(Stanford) Notes</title>
      <link>/post/2018/01/25/algorithms/</link>
      <pubDate>Thu, 25 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/01/25/algorithms/</guid>
      <description>PDF格式笔记见：Notes
Divide and Conquer 分而治之  DIVIDE into smaller sub-problems CONQUER via recursive calls COMBINE solutions of sub-problems into one for the original problem  Master Method  Cool feature: a &amp;ldquo;black-box&amp;rdquo; method for solving recurrences
 Determine the upper bound of running time for most of the D&amp;amp;C algos
 Assumption: all sub-problems have equal size
    unbalanced sub-problems? more than one recurrence?    Recurrence format:</description>
    </item>
    
    <item>
      <title>Leetcode算法题目（不断更新）</title>
      <link>/post/2018/01/25/leetcode/</link>
      <pubDate>Thu, 25 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/01/25/leetcode/</guid>
      <description>Non-decreasing Array  Given an array with $n$ integers, your task is to check if it could become non-decreasing by modifying at most 1 element.
We define an array is non-decreasing if array[i] &amp;lt;= array[i + 1] holds for every i (1 &amp;lt;= i &amp;lt; n).
 思路:
使用for loop扫描数列,假如在下标idx, idx+1处不满足非递减关系,那么:
 要么 array[idx-1]&amp;lt;=array[idx+1],此时只要判断idx+1后都满足非递减关系即可 要么array[idx-1]&amp;gt;array[idx+1],此时只要用array[idx]代替array[idx+1],再判断idx+1后都满足非递减关系即可  class Solution: def checkPossibility(self, nums): &amp;quot;&amp;quot;&amp;quot; :type nums: List[int] :rtype: bool &amp;quot;&amp;quot;&amp;quot; idx = 0 for i in range(len(nums)-1): if nums[i] &amp;gt; nums[i+1]: idx = i break if idx &amp;gt; 0 and (nums[idx-1] &amp;gt; nums[idx+1]): nums[idx+1] = nums[idx] for j in range(idx+1, len(nums)-1): if nums[j] &amp;gt; nums[j+1]: return False else: return True  Leetcode运行结果:</description>
    </item>
    
    <item>
      <title>Python Data Structures</title>
      <link>/post/2018/01/25/python-data-structure/</link>
      <pubDate>Thu, 25 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/01/25/python-data-structure/</guid>
      <description>Built-in List  See help(list)  # Create a new list empty = list() # or empty = [] # faster, more pythonic   Lists can contain elements of different types Use append to append elements to the end of a list  nums = [1,2,3] nums.append(4) # nums == [1, 2, 3, 4]   Access element at a particular index  nums[-1] # =&amp;gt; [4]   Slice lists  nums[1:-1] # =&amp;gt; [2, 3] &#39;python&#39;[:3] # =&amp;gt; &#39;pyt&#39;   Nested lists  letters = [&amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;] x = [nums, letters] x[0] # =&amp;gt; [1, 2, 3, 4] x[0][1] # =&amp;gt; 2 x[1][:2] # =&amp;gt; [&#39;a&#39;, &#39;b&#39;]   Length (len)  len(x) # =&amp;gt; 2 len([]) # =&amp;gt; 0   Membership (in)  0 in [] # =&amp;gt; False &#39;y&#39; in &#39;python&#39; # =&amp;gt; True   Palindrome?</description>
    </item>
    
    <item>
      <title>Python中的取整方式</title>
      <link>/post/2018/01/19/python-float-to-int/</link>
      <pubDate>Fri, 19 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/01/19/python-float-to-int/</guid>
      <description>方式一：round() 四舍五入 Python中的 round() 有两个参数，第一个参数是需要处理的数，第二个参数是数位精度，默认为0。
round(3.4) ## 3 round(3.5) ## 4  而有时候会出现奇怪的情况，比如：
round(3.24, 1) #是四舍五入 ## 3.2 round(3.26, 1) #是四舍五入 ## 3.3 round(3.25, 1) #不是四舍五入 ## 3.2 ################################### round(0.44, 1) #是四舍五入 ## 0.4 round(0.46, 1) #是四舍五入 ## 0.5 round(0.45, 1) #是四舍五入 ## 0.5  很多人说Python3中采用的是【四舍六入五留双】，上面的例子说明这种说法是不正确的。其实是因为：
 十进制小数在计算机内是通过二进制小数来近似，在舍和进两个选项中选择更接近的一个 而当舍和进的两个选项十分接近时，round 选择偶数的选项  这就导致出现的结果非常复杂了。
进一步解释：十进制小数 $0.2$ 和 $0.3$ 的二进制表示分别为：
$$ \begin{align} (0.2)_{10} &amp;amp; = \left(\frac{1}{8}+\frac{1}{16}\right)+\left(\frac{1}{128}+\frac{1}{256}\right)+\cdots =\frac{\frac{1}{8}+\frac{1}{16}}{1-\frac{1}{16}} =\frac{3}{15}=\frac{1}{5}\newline &amp;amp;=(0.\dot{0}\dot{0}\dot{1}\dot{1})_2 \end{align} $$
以及 $$ \begin{align} (0.</description>
    </item>
    
    <item>
      <title>Max Subarray</title>
      <link>/post/2018/01/02/max-subarray/</link>
      <pubDate>Tue, 02 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/01/02/max-subarray/</guid>
      <description> Brute Force Divide and Conquer Non-recursive Linear Method </description>
    </item>
    
    <item>
      <title>Python Type Conversion</title>
      <link>/post/2018/01/01/python-type-conversion/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/01/01/python-type-conversion/</guid>
      <description>Types  Variables in Python are dynamically-typed: declared without an explicit type. objects have a type, so Python knows the type of a variable. No char in Python! Both &#39; and &amp;quot; create string literals  type(1) # &amp;lt;class &#39;int&#39;&amp;gt; type(1.0) # &amp;lt;class &#39;float&#39;&amp;gt; type(2/1) # &amp;lt;class &#39;float&#39;&amp;gt; type(&amp;quot;hello&amp;quot;) # &amp;lt;class &#39;str&#39;&amp;gt; type(&#39;a&#39;) # &amp;lt;class &#39;str&#39;&amp;gt; type(True) # &amp;lt;class &#39;bool&#39;&amp;gt; type(None) # &amp;lt;class &#39;NoneType&#39;&amp;gt; type(int) # &amp;lt;class &#39;type&#39;&amp;gt; type(type(int)) # &amp;lt;class &#39;type&#39;&amp;gt; type(print) # &amp;lt;class &#39;builtin_function_or_method&#39;&amp;gt;   bool is a subtype of int, where True == 1 and False == 0  True == 1 # True False == 0 # True True == 2 # False True or False # True (short-circuits)  Truthy and Falsy # &#39;Falsy&#39; bool(None) bool(False) bool(0) bool(0.</description>
    </item>
    
    <item>
      <title>Python练习题（不断更新）</title>
      <link>/post/2018/01/01/python-exercises/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/01/01/python-exercises/</guid>
      <description>基础 Tic-tac-toe  Write a program using print() that, when run, prints out a tic-tac-toe board.   | | -------- | | -------- | |   Write a program that, when run, prints out a SUPER tic-tac-toe board.   | | H | | H | | --+--+--H--+--+--H--+--+-- | | H | | H | | --+--+--H--+--+--H--+--+-- | | H | | H | | ========+========+======== | | H | | H | | --+--+--H--+--+--H--+--+-- | | H | | H | | --+--+--H--+--+--H--+--+-- | | H | | H | | ========+========+======== | | H | | H | | --+--+--H--+--+--H--+--+-- | | H | | H | | --+--+--H--+--+--H--+--+-- | | H | | H | |  数据结构 算法 Greatest Common Divisor 最大公因数 Euclid&amp;rsquo;s algorithm:</description>
    </item>
    
    <item>
      <title>Sorting 排序算法</title>
      <link>/post/2018/01/01/sorting/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/01/01/sorting/</guid>
      <description>Visualization of Sorting Algorithms https://www.cs.usfca.edu/~galles/visualization/ComparisonSort.html
https://visualgo.net/bn/sorting
https://www.toptal.com/developers/sorting-algorithms
References http://i.cs.hku.hk/~hkual/Notes/SearchingSorting/SortingSearchingSelection.html
https://cs.stackexchange.com/questions/13106/why-is-selection-sort-faster-than-bubble-sort
Summary     Best-Case $T(n)$ Worst-Case $T(n)$ Average-Case $T(n)$? Space Complexity     Bubble Sort $O(n)$ $O(n^2)$ $O(n^2)$ $O(1)$   Selection Sort $O(n^2)$ $O(n^2)$ $O(n^2)$ $O(1)$   Insertion Sort $O(n)$ $O(n^2)$ $O(n^2)$ $O(1)$   Merge Sort $O(n\log n)$ $O(n\log n)$ $O(n\log n)$ $O(n)$   Quick Sort $O(n\log n)$ $O(n^2)$ $O(n\log n)$ ?</description>
    </item>
    
    <item>
      <title>ML - Application Example - Photo OCR</title>
      <link>/post/2017/11/11/ocr/</link>
      <pubDate>Sat, 11 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/11/ocr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ML - Large Scale Machine Learning</title>
      <link>/post/2017/11/10/large-scale-ml/</link>
      <pubDate>Fri, 10 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/10/large-scale-ml/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ML - Recommender Systems</title>
      <link>/post/2017/11/09/recommender-systems/</link>
      <pubDate>Thu, 09 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/09/recommender-systems/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ML - Anomaly Detection</title>
      <link>/post/2017/11/08/anomaly/</link>
      <pubDate>Wed, 08 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/08/anomaly/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ML - Dimensionality Reduction</title>
      <link>/post/2017/11/08/dimension-reduction/</link>
      <pubDate>Wed, 08 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/08/dimension-reduction/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ML - Unsupervised Learning</title>
      <link>/post/2017/11/07/unsupervised/</link>
      <pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/07/unsupervised/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ML - Support Vector Machines</title>
      <link>/post/2017/11/06/svms/</link>
      <pubDate>Mon, 06 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/06/svms/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ML - Machine Learning System Design</title>
      <link>/post/2017/11/05/system-design/</link>
      <pubDate>Sun, 05 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/05/system-design/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ML - Neural Networks</title>
      <link>/post/2017/11/04/neural-networks/</link>
      <pubDate>Sat, 04 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/04/neural-networks/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ML - Regularization</title>
      <link>/post/2017/11/03/regularization/</link>
      <pubDate>Fri, 03 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/03/regularization/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ML - Logistic Regression</title>
      <link>/post/2017/11/02/logistic/</link>
      <pubDate>Thu, 02 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/02/logistic/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ML - Linear Regression with Multiple Variables</title>
      <link>/post/2017/11/01/lr/</link>
      <pubDate>Wed, 01 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/01/lr/</guid>
      <description>Linear Regression with One Variable  $X$: space of input values, $Y$: space of output values
 training set $\{(x^{(i)}, y^{(i)})\}_{i=1}^m$
 goal: given a training set, to learn a function $h : X \rightarrow Y$ so that $h(x)$ is a “good” predictor for the corresponding value of $y$. For historical reasons, this function $h$ is called a hypothesis.
 $h(x)=h_{\theta}(x) = \theta_0 + \theta_1 x$
 cost function (squared error function, or mean squared error, MSE):</description>
    </item>
    
  </channel>
</rss>