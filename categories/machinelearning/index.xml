<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>MachineLearning on NOWHERESVILLE</title>
    <link>/categories/machinelearning/</link>
    <description>Recent content in MachineLearning on NOWHERESVILLE</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 14 Feb 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="/categories/machinelearning/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Kaggle - House Prices</title>
      <link>/post/2018/02/14/kaggle-house-prices/</link>
      <pubDate>Wed, 14 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/02/14/kaggle-house-prices/</guid>
      <description>EDA附录：数据描述EDA附录：数据描述SalePrice - the property’s sale price in dollars. This is the target variable that you’re trying to predict.MSSubClass: The building classMSZoning: The general zoning classificationLotFrontage: Linear feet of street connected to propertyLotArea: Lot size in square feetStreet: Type of road accessAlley: Type of alley accessLotShape: General shape of propertyLandContour: Flatness of the propertyUtilities: Type of utilities availableLotConfig: Lot configurationLandSlope: Slope of propertyNeighborhood: Physical locations within Ames city limitsCondition1: Proximity to main road or railroadCondition2: Proximity to main road or railroad (if a second is present)BldgType: Type of dwellingHouseStyle: Style of dwellingOverallQual: Overall material and finish qualityOverallCond: Overall condition ratingYearBuilt: Original construction dateYearRemodAdd: Remodel dateRoofStyle: Type of roofRoofMatl: Roof materialExterior1st: Exterior covering on houseExterior2nd: Exterior covering on house (if more than one material)MasVnrType: Masonry veneer typeMasVnrArea: Masonry veneer area in square feetExterQual: Exterior material qualityExterCond: Present condition of the material on the exteriorFoundation: Type of foundationBsmtQual: Height of the basementBsmtCond: General condition of the basementBsmtExposure: Walkout or garden level basement wallsBsmtFinType1: Quality of basement finished areaBsmtFinSF1: Type 1 finished square feetBsmtFinType2: Quality of second finished area (if present)BsmtFinSF2: Type 2 finished square feetBsmtUnfSF: Unfinished square feet of basement areaTotalBsmtSF: Total square feet of basement areaHeating: Type of heatingHeatingQC: Heating quality and conditionCentralAir: Central air conditioningElectrical: Electrical system1stFlrSF: First Floor square feet2ndFlrSF: Second floor square feetLowQualFinSF: Low quality finished square feet (all floors)GrLivArea: Above grade (ground) living area square feetBsmtFullBath: Basement full bathroomsBsmtHalfBath: Basement half bathroomsFullBath: Full bathrooms above gradeHalfBath: Half baths above gradeBedroom: Number of bedrooms above basement levelKitchen: Number of kitchensKitchenQual: Kitchen qualityTotRmsAbvGrd: Total rooms above grade (does not include bathrooms)Functional: Home functionality ratingFireplaces: Number of fireplacesFireplaceQu: Fireplace qualityGarageType: Garage locationGarageYrBlt: Year garage was builtGarageFinish: Interior finish of the garageGarageCars: Size of garage in car capacityGarageArea: Size of garage in square feetGarageQual: Garage qualityGarageCond: Garage conditionPavedDrive: Paved drivewayWoodDeckSF: Wood deck area in square feetOpenPorchSF: Open porch area in square feetEnclosedPorch: Enclosed porch area in square feet3SsnPorch: Three season porch area in square feetScreenPorch: Screen porch area in square feetPoolArea: Pool area in square feetPoolQC: Pool qualityFence: Fence qualityMiscFeature: Miscellaneous feature not covered in other categoriesMiscVal: Value of miscellaneous featureMoSold: Month SoldYrSold: Year SoldSaleType: Type of saleSaleCondition: Condition of sale</description>
    </item>
    
    <item>
      <title>Kaggle - Titanic</title>
      <link>/post/2018/02/13/kaggle-titanic/</link>
      <pubDate>Tue, 13 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/02/13/kaggle-titanic/</guid>
      <description>EDAEDA</description>
    </item>
    
    <item>
      <title>Data Manipulation at Scale 大规模数据处理</title>
      <link>/post/2018/02/01/data-manipulation-at-scale/</link>
      <pubDate>Thu, 01 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>/post/2018/02/01/data-manipulation-at-scale/</guid>
      <description>课程介绍  Data Manipulation at Scale: Systems and Algorithms 大规模数据处理：系统和算法【 Coursera链接 】 Data Science at Scale Specialization 的第一门课，共4门 制作方： University of Washington 教学方： Bill Howe  Twitter Sentiment Analysis 情感分析 分析目的  access the twitter Application Programming Interface(API) using python estimate the public&amp;rsquo;s perception (the sentiment) of a particular term or phrase analyze the relationship between location and mood based on a sample of twitter data  步骤  CLI安装 oauth2 package [用于授权登录]  pip3 install oauth2   创建 twitter 账号 到 https://apps.</description>
    </item>
    
    <item>
      <title>Time Series Analysis 学习笔记</title>
      <link>/post/2017/12/01/time-series/</link>
      <pubDate>Fri, 01 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/12/01/time-series/</guid>
      <description>参考资料参考资料</description>
    </item>
    
    <item>
      <title>ML - Application Example - Photo OCR</title>
      <link>/post/2017/11/11/ocr/</link>
      <pubDate>Sat, 11 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/11/ocr/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ML - Large Scale Machine Learning</title>
      <link>/post/2017/11/10/large-scale-ml/</link>
      <pubDate>Fri, 10 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/10/large-scale-ml/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ML - Recommender Systems</title>
      <link>/post/2017/11/09/recommender-systems/</link>
      <pubDate>Thu, 09 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/09/recommender-systems/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ML - Anomaly Detection</title>
      <link>/post/2017/11/08/anomaly/</link>
      <pubDate>Wed, 08 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/08/anomaly/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ML - Dimensionality Reduction</title>
      <link>/post/2017/11/08/dimension-reduction/</link>
      <pubDate>Wed, 08 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/08/dimension-reduction/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ML - Unsupervised Learning</title>
      <link>/post/2017/11/07/unsupervised/</link>
      <pubDate>Tue, 07 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/07/unsupervised/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ML - Support Vector Machines</title>
      <link>/post/2017/11/06/svms/</link>
      <pubDate>Mon, 06 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/06/svms/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ML - Machine Learning System Design</title>
      <link>/post/2017/11/05/system-design/</link>
      <pubDate>Sun, 05 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/05/system-design/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ML - Neural Networks</title>
      <link>/post/2017/11/04/neural-networks/</link>
      <pubDate>Sat, 04 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/04/neural-networks/</guid>
      <description> Model Representation $$ a_i^{[j]} = \text{&amp;ldquo;activation&amp;rdquo; of unit $i$ in layer $j$} \\
\Theta^{[j]} = \text{matrix of weights controlling function mapping from layer $j$ to layer $j+1$} $$
Forward Propagation: Vectorized Implementation $$ [x] \rightarrow [a^{[2]}] \rightarrow [a^{[3]}]\rightarrow \cdots $$
 input: $x$. Setting $a^{[1]}=x$ linear combination: $z^{[j]}=\Theta^{[j-1]}a^{[j-1]}, \ \ j=2,3,\ldots$ activation: $a^{[j]}=g(z^{[j]}), \ \ j=2,3,\ldots$  Non-linear Classification Example: XNOR operator    x1 x2 XNOR = NOT XOR     0 0 1   0 1 0   1 0 0   1 1 1     using a hidden layer with two nodes (sigmoid activation function)  Multiclass Classification </description>
    </item>
    
    <item>
      <title>ML - Logistic Regression</title>
      <link>/post/2017/11/02/logistic/</link>
      <pubDate>Thu, 02 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/02/logistic/</guid>
      <description>Logistic Regression Model  goal: want $h_{\theta}(x) \in [0,1]$ $h_{\theta}(x)=g(\theta^Tx)$, where $g(z)=\frac{1}{1+e^{-z}}$ (sigmoid function/ logistic function) interpretations: $h_{\theta}(x)$ = estimated probability that $y=1$ on input $x$, that is  $$h(x)=h_{\theta}(x) = \Pr(y=1|x;\theta)$$
 prediction: predict $y=1$ if $h_{\theta}(x)\geq 0.5 \Leftrightarrow \theta^Tx\geq 0$
 Decision Boundary: $\theta^Tx= 0$
 Nonlinear Decision Boundary: add complex (i.e. polynomial) terms
 Notations: training set $\{(x^{(i)}, y^{(i)})\}_{i=1}^N$, where
  $$ x = \begin{pmatrix}x_0\newline x_1\newline\vdots\newline x_p\end{pmatrix}\in\mathbb{R}^{p+1}, x_0=1,y\in\{0,1\} $$</description>
    </item>
    
    <item>
      <title>ML - Linear Regression with Multiple Variables</title>
      <link>/post/2017/11/01/lr/</link>
      <pubDate>Wed, 01 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/11/01/lr/</guid>
      <description>Linear Regression with One Variable  $X$: space of input values, $Y$: space of output values
 training set $\{(x^{(i)}, y^{(i)})\}_{i=1}^N$
 goal: given a training set, to learn a function $h : X \rightarrow Y$ so that $h(x)$ is a “good” predictor for the corresponding value of $y$. For historical reasons, this function $h$ is called a hypothesis.
 $h(x)=h_{\theta}(x) = \theta_0 + \theta_1 x$
 cost function (squared error function, or mean squared error, MSE):</description>
    </item>
    
    <item>
      <title>ISLR CH10 Unsupervised Learning</title>
      <link>/post/2017/10/10/unsupervised/</link>
      <pubDate>Tue, 10 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/10/10/unsupervised/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ISLR CH9 Support Vector Machines</title>
      <link>/post/2017/10/09/svm/</link>
      <pubDate>Mon, 09 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/10/09/svm/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ISLR CH8 Tree-Based Methods</title>
      <link>/post/2017/10/08/tree-based-methods/</link>
      <pubDate>Sun, 08 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/10/08/tree-based-methods/</guid>
      <description>IntuitionModelsRegression TreesPredicting Baseball Players’ SalariesAlgorithmTree PruningReferencesIntuitionRegression/Classification
Stratify or segment the predictor space into simple regions
Prediction for a given observation: mean or mode of the training observations in the region to which it belongs
The set of splitting rules can be summarized in a tree \(\Rightarrow\) Decision Tree Methods
Pros: simple, easy to interpret, and nice to visualize</description>
    </item>
    
    <item>
      <title>ISLR CH7 Moving Beyond Linearity</title>
      <link>/post/2017/10/07/beyond-linearity/</link>
      <pubDate>Sat, 07 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/10/07/beyond-linearity/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ISLR CH6 Linear Model Selection and Regularization</title>
      <link>/post/2017/10/06/model-selection/</link>
      <pubDate>Fri, 06 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/10/06/model-selection/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ISLR CH5 Resampling Method</title>
      <link>/post/2017/10/05/resampling/</link>
      <pubDate>Thu, 05 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/10/05/resampling/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ISLR CH4 Classification</title>
      <link>/post/2017/10/04/classification/</link>
      <pubDate>Wed, 04 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/10/04/classification/</guid>
      <description></description>
    </item>
    
    <item>
      <title>ISLR CH3 Linear Regression</title>
      <link>/post/2017/10/03/linear-regression/</link>
      <pubDate>Tue, 03 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>/post/2017/10/03/linear-regression/</guid>
      <description></description>
    </item>
    
  </channel>
</rss>